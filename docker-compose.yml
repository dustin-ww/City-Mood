version: "3.9"

services:
  # PostgreSQL Database
  postgres:
    image: postgres:16
    container_name: postgres
    hostname: postgres
    environment:
      POSTGRES_USER: spark
      POSTGRES_PASSWORD: spark
      POSTGRES_DB: city_mood
    ports:
      - "5432:5432"
    volumes:
      - ./sql/init.sql:/docker-entrypoint-initdb.d/init.sql
      - postgres-data:/var/lib/postgresql/data
    networks:
      - spark-network

  # Kafka Broker
  kafka:
    image: apache/kafka:4.1.1
    container_name: kafka
    hostname: kafka
    ports:
      - "9092:9092"     # internal access
      - "29092:29092"   # external access
    environment:

      # ---- KRaft ----
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      # ---- Listener config ----
      KAFKA_LISTENERS: >
        PLAINTEXT://0.0.0.0:9092,
        EXTERNAL://0.0.0.0:29092,
        CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: >
        PLAINTEXT://kafka:9092,
        EXTERNAL://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: >
        PLAINTEXT:PLAINTEXT,
        EXTERNAL:PLAINTEXT,
        CONTROLLER:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      # ---- single-node ----
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      # ---- Storage ----
      KAFKA_LOG_DIRS: /var/lib/kafka/data
    volumes:
      - kafka-data:/var/lib/kafka/data
    networks:
      - spark-network


  # Kafka UI
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    hostname: kafka-ui
    depends_on:
      - kafka
    ports:
      - "8090:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    networks:
      - spark-network

  # Spark Master
  spark-master:
    image: apache/spark:3.5.1
    container_name: spark-master
    hostname: spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
      - SPARK_PUBLIC_DNS=localhost
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - ./spark-apps:/opt/spark-apps
      - ./spark-data:/opt/spark-data
      - ./spark-logs:/opt/spark/logs
    networks:
      - spark-network

  # Spark Worker
  spark-worker:
    image: apache/spark:3.5.1
    container_name: spark-worker
    hostname: spark-worker
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_WEBUI_PORT=8081
      - SPARK_PUBLIC_DNS=localhost
    depends_on:
      - spark-master
    ports:
      - '8081:8081'
    volumes:
      - ./spark-apps:/opt/spark-apps
      - ./spark-data:/opt/spark-data
      - ./spark-logs:/opt/spark/logs
    networks:
      - spark-network

  # PySpark Client
  pyspark:
    image: apache/spark:3.5.1
    container_name: pyspark-client
    hostname: pyspark-client
    entrypoint: ["/bin/bash"]
    stdin_open: true
    tty: true
    depends_on:
      - spark-master
      - postgres
      - kafka
    volumes:
      - ./app:/opt/spark-apps
      - ./data:/opt/spark-data
      - ./gx-reports:/app/gx-reports
    networks:
      - spark-network

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    hostname: grafana
    ports:
      - "3000:3000"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: "admin"  
      GF_DATABASE_TYPE: "sqlite3"
    depends_on:
      - postgres
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning/datasources:/etc/grafana/provisioning/datasources
      - ./grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/dashboards:/var/lib/grafana/dashboards
    networks:
      - spark-network

  scheduler:
    build:
      context: .
      dockerfile: app/services/scheduler/Dockerfile
    image: city-mood-scheduler
    networks:
      - spark-network
    depends_on:
      - kafka

  


volumes:
  postgres-data:
  kafka-data:
  grafana-data:

networks:
  spark-network:
    driver: bridge
    name: spark-network
    